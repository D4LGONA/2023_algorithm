#중간고사 대비

알고리즘 : 문제를 해결하기 위한 단계적인 절차. 요리법과 유사함. 효율적인 알고리즘을 고안하는 것이 중요함
요구사항을 '어떻게' 해결할 것인가의 어떻게를 맡고 있습니다

1.1 최대 숫자 찾기
 - 순차탐색(모든 숫자를 찾아봄) O(n)
 - 이진탐색 O(logn) : 정렬된 데이터.
 - 해시테이블 O(1)

1.3 동전 거스름돈(가장 적은 수의 동전으로 거슬러주기) : Greedy로 푼다고 하네요 -> 나중에 배울 것

1.4 한붓 그리기 : 오일러 서킷
 - 연결된 선이 홀수개인 녀석이 몇개 있는지 보고 가능한지 알 수 있음
 - 2개는 가능, 4개 이상은 불가능. 연결된 선이 홀수개인 녀석이 1개만 있거나 3개만 있는건 불가능함(짝수 자체가 불가능함)
 - back tracking : 무식하게 다 해보는 것
 - 해결: 길이 한개일때 그 길로 간다, 여러개일때는 현재 점으로 돌아오는 사이클이 있으면 진행한다.
           사이클이 있다: 해당 간선을 지우고 다른 방법으로 그 점에 갈 수 있으면 사이클이 있음

1.5 미로 찾기 - 실타래 ?
 - 벽을 종이상자라고 생각하고 일자로 만들면 풀 수 있음(오른손의 법칙...) 문제의 본질이 해쳐지면 안됨

1.6 가짜 동전 찾기 : 분할정복
 - 철수 : 하나하나 탐색 O(n)
 - 영희 : 두개씩 비교 O(n/2) == O(n)
 - 광수 : 뭉탱이 O(logn)

1.7 독이 든 술단지 : 이진수
 - 2진수 변환해서 먹이고 누가 죽었는지 확인하는거

- 2장 -

알고리즘의 일반적 특성
 - 정확성 : 주어진 입력에 대해 올바른 해
 - 수행성 : 컴퓨터에서 수행 가능
 - 유한성 : 유한시간 내에 종료
 - 효율성 : 효율적일수록 가치 상승

2.2 최초의 알고리즘 : 유클리드의 최대공약수 알고리즘
 - 2개의 자연수의 최대공약수는 큰 수에서 작은수를 뺀 수와 작은수의 최대공약수와 같다
 - 이걸 재귀함수로 돌려서 계속 뺀다. 하나가 0이 될 때까지 인듯

2.3 알고리즘의 표현 방법 : 프로그래밍 언어와 비슷한 의사 코드(pseudo code)로 표현, 빨리 쓰려고 사용
 - 플로우 차트, 자연어, 특정언어, 슈도 코드

2.4 알고리즘의 분류

2.5 알고리즘의 효율성 표현
알고리즘의 효율성
 - 알고리즘의 수행시간 또는 알고리즘이 수행하는 동안 사용되는 메모리 크기
 - 시간복잡도, 공간복잡도 (+개발.. 복잡도? 내가 쓸거면 개발복잡도가 낮은 걸로 ㅋㅋ)
 - 일반적으로 알고리즘을 비교할때는 시간복잡도를 주로 사용 -> 알고리즘이 수행하는 기본적인 연산 횟수를 입력 크기에 대한 함수로 표현

알고리즘의 복잡도 표현 방법
: 최악 경우 분석
 - 보통 이것을 사용, 어떤 입력이 주어지더라도 알고리즘의 수행시간이 얼마 이상 넘지 않는다는 상한의 의미.
: 평균 경우 분석
 - 퀵 정렬 평균 O(nlogn)
: 최선 경우 분석
 - 삽입정렬 최선 O(n)

2.6 복잡도의 점근적 표기
: 시간복잡도는 입력 크기에 대한 함수로 표기
 - 점근적 표기를 사용 -> n이 무한대로 갈때 복잡도를 간단히 표현하는 표기법
O(1), O(logn), O(n), O(nlogn), O(n^2), ... O(2^n) O(n!)
big O : 상한
big omega: 하한
big theta: 둘다만족 -> 다항식에서 최고 차수 항만을 취한 뒤 그 항의 계수를 제거하여 g(n)을 정한다. ** bigO가 나왔을때 theta인지 진짜 O인지 잘 확인해 보도록
O-표기의 포함관계...
효율적 알고리즘의 필요성...

- 6장 -

내부정렬: 메모리에 올릴수있는것
외부정렬: 메모리에 못올리는거
정렬 알고리즘의 최선 최악 평균 시간복잡도, 메모리, stable 여부. 최근엔 Timsort를 많이 사용(mergesort + insertion sort), quick sort는 stable 하지 않음)
퀵소트는 왜 logn만큼 메모리가 필요한가요 -> 재귀함수가 쓰는 메모리요

6.1 버블정렬
이웃하는 숫자를 비교하여 작은 수를 앞쪽으로 이동시키는 과정을 반복하여 정렬
만들기 쉽지만 느림, 성능개선 하면 좀 빨라지기도 함, 최선 O(n): 정렬돼있을때, 평균/최악 O(n^2)

6.2 선택정렬
입력 배열 전체에서 최솟값을 선택해서 맨 앞으로...
항상 일정한 시간 복잡도, 입력에 민감하지 않은 알고리즘. 원소간의 자리바꿈 횟수가 최소
임의의 데이터일때 O(n^2)알고리즘 중 가장 빠름

6.3. 삽입정렬
주인공을 왼쪽으로 보낸다... 첫번째 숫자는 주인공 시켜줄 필요 없다
피신시켜놨다 밀기만하고 피신시킨애를 다시 갖다놓음
최악 O(n^2), 최선O(n)

6.4. 쉘정렬 -> 사람이름에서 유래
한번에 여러칸 이동, gap이라는 개념 이동
gap개의 subarray로 나누고 각각의 subarray에 삽입정렬을 함
3중 루프
시간복잡도 대략 O(n^1.5)
쉘정렬 vs 힙정렬
-> 쉘정렬이 오히려 빨랐다. 개수가 적을땐 쉘정렬이 빠름

6.5 힙정렬
이진트리... 이진 힙...
다운힙은 큰숫자부터 차례대로. 왼쪽트리 오른쪽트리 둘다 힙상태여야 가능. 자식이 있는 노드만 다운힙 n/2부터 시작
루트가 1일때 부모 i/2, 왼쪽자식 2i, 오른쪽자식 2i+1
최대힙 만든다
루트와 힙의 가장 마지막 노드 교환
힙 크기를 한개 줄임.
다시 다운힙해서 힙상태 만듦
반복.
다운힙 하는 법: 왼자식 오른자식 비교 나보다 큰놈이랑 바꿈 자식없을때까지 반복 -> 머랑 머랑 교환하는지 문제 나온다는 데요?
힙 만드는데 O(n), 다운힙에 O(logn)
이론상 완벽함 시간복잡도가 일정하고 메모리도 안쓰기 때문.. 그러나 캐시 미스때문에 더 느려짐 ㅠㅠ

6.6 정렬문제의 하한
기수정렬? count정렬 -> 특정 조건에만 가능
"" 비교정렬 문제의 하한은 O(nlogn) ""

결정트리 ???? 결정트리의 높이가 정렬문제의 하한이 됨 따라서 O(nlogn) 이라네요...

기수정렬

붖할정복 ㅏㄹ고리즘

3.1 합병정렬
왼쪽절반정렬 - 오른쪽절반정렬 - 합병
원소가 1개인 배열은 다 정렬된 것
n번의 비교를 깊이 logn -> O(nlogn)
공간복잡도 O(n)이라는 것이 단점임
stable

3.2 퀵정렬
파티션 - 퀵소트 - 퀵소트
분할 정복 알고리즘이지만 정복 후 분할하는 알고리즘, 분할된 문제를 취합하는 부분이 없음
최선경우 O(nlogn) 최악경우 O(n)
피봇 선정하는 방법들 ...
반반으로 나눠지게끔 하는거 -> 개수가 많을때만 함

3.3 선택문제
100개중 30번째를 찾아라. pivot이 50번째이면 어디서 찾냐 - 왼쪽그룹 이런식
0부터 시작하는지 1부터 시작하는지?

3.4 최근접 점의 쌍 찾기
분할정복 이용. 취합할때 중간 영역을 고려해야 함. 
교재에는 nlog^2n인데 y좌표로 정렬된애를 따로 만들어서 strip을 가져올때 그 배열에서 가져와
그러면 nlogn이아니고 n만큼 시간이 걸려서 nlogn이 되게 됨

3.5 분할정복이 부적절한 부분?
-> 피보나치 수열, 쪼개면 쪼갤수록 더 많아짐 ㅠㅠ
취합과정도 주의해야 한다는데요



















